import os
import re
import yaml
import requests
import json
import time
from typing import List, Dict, Tuple, Optional
from datetime import datetime
import streamlit as st
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.units import inch
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import io

from progress_manager import ProgressManager, TaskProgress


class AIModelClient:
    """ç»Ÿä¸€çš„AIæ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ”¯æŒOpenAI APIé£æ ¼çš„å¤šç§æ¨¡å‹"""
    
    def __init__(self, model_config: Dict, retry_config: Dict = None):
        self.config = model_config
        self.base_url = model_config['base_url'].rstrip('/')
        self.api_key = model_config['api_key']
        self.model = model_config['model']
        self.max_tokens = model_config.get('max_tokens', 4000)
        self.temperature = model_config.get('temperature', 0.3)
        
        # é‡è¯•é…ç½®
        self.retry_config = retry_config or {}
        self.max_attempts = self.retry_config.get('max_attempts', 3)
        self.delay_seconds = self.retry_config.get('delay_seconds', 5)
        self.exponential_backoff = self.retry_config.get('exponential_backoff', True)
        self.timeout_seconds = self.retry_config.get('timeout_seconds', 60)
    
    def _is_anthropic_api(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºAnthropic Claude API"""
        return 'anthropic.com' in self.base_url
    
    def _calculate_delay(self, attempt: int) -> float:
        """è®¡ç®—é‡è¯•å»¶è¿Ÿæ—¶é—´"""
        if self.exponential_backoff:
            return self.delay_seconds * (2 ** (attempt - 1))
        return self.delay_seconds
    
    def call_api(self, messages: List[Dict], system_prompt: str = "") -> str:
        """è°ƒç”¨AI APIè¿›è¡Œæ–‡æœ¬ç”Ÿæˆï¼ŒåŒ…å«é‡è¯•æœºåˆ¶"""
        last_error = None
        
        for attempt in range(1, self.max_attempts + 1):
            try:
                headers = {
                    'Content-Type': 'application/json'
                }
                
                # æ ¹æ®ä¸åŒAPIè®¾ç½®è®¤è¯å¤´
                if self._is_anthropic_api():
                    headers['x-api-key'] = self.api_key
                    headers['anthropic-version'] = '2023-06-01'
                    
                    # Claude APIæ ¼å¼
                    data = {
                        'model': self.model,
                        'max_tokens': self.max_tokens,
                        'temperature': self.temperature,
                        'messages': messages
                    }
                    if system_prompt:
                        data['system'] = system_prompt
                    
                    url = f"{self.base_url}/messages"
                else:
                    # OpenAI APIæ ¼å¼
                    headers['Authorization'] = f'Bearer {self.api_key}'
                    
                    # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
                    api_messages = []
                    if system_prompt:
                        api_messages.append({"role": "system", "content": system_prompt})
                    api_messages.extend(messages)
                    
                    data = {
                        'model': self.model,
                        'messages': api_messages,
                        'max_tokens': self.max_tokens,
                        'temperature': self.temperature
                    }
                    
                    url = f"{self.base_url}/chat/completions"
                
                response = requests.post(url, headers=headers, json=data, timeout=self.timeout_seconds)
                response.raise_for_status()
                
                result = response.json()
                
                # è§£æä¸åŒAPIçš„å“åº”æ ¼å¼
                if self._is_anthropic_api():
                    return result['content'][0]['text']
                else:
                    return result['choices'][0]['message']['content']
                    
            except requests.exceptions.Timeout as e:
                last_error = f"è¯·æ±‚è¶…æ—¶ (ç¬¬{attempt}æ¬¡å°è¯•): {str(e)}"
                
            except requests.exceptions.RequestException as e:
                # æ£€æŸ¥æ˜¯å¦ä¸ºé€Ÿç‡é™åˆ¶é”™è¯¯
                if hasattr(e, 'response') and e.response is not None:
                    if e.response.status_code == 429:  # é€Ÿç‡é™åˆ¶
                        last_error = f"APIé€Ÿç‡é™åˆ¶ (ç¬¬{attempt}æ¬¡å°è¯•): {str(e)}"
                    elif e.response.status_code >= 500:  # æœåŠ¡å™¨é”™è¯¯
                        last_error = f"æœåŠ¡å™¨é”™è¯¯ (ç¬¬{attempt}æ¬¡å°è¯•): {str(e)}"
                    else:
                        # å®¢æˆ·ç«¯é”™è¯¯ï¼Œé€šå¸¸ä¸éœ€è¦é‡è¯•
                        raise Exception(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
                else:
                    last_error = f"ç½‘ç»œé”™è¯¯ (ç¬¬{attempt}æ¬¡å°è¯•): {str(e)}"
                    
            except KeyError as e:
                raise Exception(f"APIå“åº”æ ¼å¼é”™è¯¯: {str(e)}")
                
            except Exception as e:
                last_error = f"æœªçŸ¥é”™è¯¯ (ç¬¬{attempt}æ¬¡å°è¯•): {str(e)}"
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œåˆ™ç­‰å¾…åé‡è¯•
            if attempt < self.max_attempts:
                delay = self._calculate_delay(attempt)
                st.info(f"ç¬¬{attempt}æ¬¡å°è¯•å¤±è´¥ï¼Œ{delay:.1f}ç§’åé‡è¯•... ({last_error})")
                time.sleep(delay)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        raise Exception(f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯•{self.max_attempts}æ¬¡: {last_error}")


class TextSegmenter:
    """æ™ºèƒ½æ–‡æœ¬åˆ†æ®µå™¨ï¼ŒåŸºäºä¸»é¢˜è¿›è¡Œåˆ†æ®µ"""
    
    def __init__(self, min_length: int = 300, max_length: int = 1500, overlap_ratio: float = 0.1):
        self.min_length = min_length
        self.max_length = max_length
        self.overlap_ratio = overlap_ratio
    
    def segment_by_topic(self, text: str) -> List[Dict]:
        """åŸºäºä¸»é¢˜æ™ºèƒ½åˆ†æ®µ"""
        # é¦–å…ˆæŒ‰æ®µè½åˆ†å‰²
        paragraphs = [p.strip() for p in text.split('\n') if p.strip()]
        
        segments = []
        current_segment = ""
        current_length = 0
        segment_start_time = None
        
        for i, paragraph in enumerate(paragraphs):
            # æ£€æµ‹æ—¶é—´æˆ³ï¼ˆç”¨äºæ’­å®¢è½¬å½•ï¼‰
            time_match = re.search(r'\[(\d{1,2}):(\d{2}):(\d{2})\]', paragraph)
            if time_match and not segment_start_time:
                segment_start_time = f"{time_match.group(1)}:{time_match.group(2)}:{time_match.group(3)}"
            
            paragraph_length = len(paragraph)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºä¸»é¢˜è½¬æ¢ç‚¹
            is_topic_change = self._detect_topic_change(paragraph)
            
            # åˆ†æ®µæ¡ä»¶ï¼š
            # 1. è¾¾åˆ°æœ€å¤§é•¿åº¦
            # 2. æ£€æµ‹åˆ°ä¸»é¢˜è½¬æ¢ä¸”å·²è¾¾åˆ°æœ€å°é•¿åº¦
            # 3. æ˜¯æœ€åä¸€ä¸ªæ®µè½
            should_split = (
                current_length + paragraph_length > self.max_length or
                (is_topic_change and current_length >= self.min_length) or
                i == len(paragraphs) - 1
            )
            
            if should_split and current_segment:
                # æ·»åŠ å½“å‰æ®µè½åˆ°åˆ†æ®µä¸­
                if i < len(paragraphs) - 1:  # ä¸æ˜¯æœ€åä¸€ä¸ªæ®µè½
                    current_segment += "\n" + paragraph
                
                segments.append({
                    'content': current_segment.strip(),
                    'start_time': segment_start_time,
                    'length': len(current_segment),
                    'index': len(segments) + 1
                })
                
                # é‡ç½®å¹¶å¼€å§‹æ–°åˆ†æ®µ
                if i < len(paragraphs) - 1:  # ä¸æ˜¯æœ€åä¸€ä¸ªæ®µè½
                    overlap_length = int(len(current_segment) * self.overlap_ratio)
                    current_segment = current_segment[-overlap_length:] + "\n" + paragraph
                    current_length = len(current_segment)
                    segment_start_time = None
                else:
                    # æœ€åä¸€ä¸ªæ®µè½ï¼Œæ·»åŠ åˆ°å½“å‰æ®µè½
                    current_segment += "\n" + paragraph
                    segments[-1]['content'] = current_segment.strip()
                    segments[-1]['length'] = len(current_segment)
            else:
                # ç»§ç»­æ·»åŠ åˆ°å½“å‰åˆ†æ®µ
                if current_segment:
                    current_segment += "\n" + paragraph
                else:
                    current_segment = paragraph
                current_length = len(current_segment)
        
        # å¤„ç†å‰©ä½™å†…å®¹
        if current_segment and not segments:
            segments.append({
                'content': current_segment.strip(),
                'start_time': segment_start_time,
                'length': len(current_segment),
                'index': 1
            })
        
        return segments
    
    def _detect_topic_change(self, paragraph: str) -> bool:
        """æ£€æµ‹ä¸»é¢˜è½¬æ¢çš„ç®€å•è§„åˆ™"""
        # ä¸»é¢˜è½¬æ¢æŒ‡ç¤ºè¯
        topic_indicators = [
            'æ¥ä¸‹æ¥', 'ç„¶å', 'å¦å¤–', 'æ­¤å¤–', 'æ¢ä¸ªè¯é¢˜', 'è¯´åˆ°', 
            'è°ˆåˆ°', 'å…³äº', 'æˆ‘ä»¬å†æ¥çœ‹', 'ä¸‹é¢', 'ç°åœ¨', 'æœ€å',
            'æ€»ç»“', 'æ€»çš„æ¥è¯´', 'ç»¼ä¸Š'
        ]
        
        # é—®ç­”æ¨¡å¼æ£€æµ‹
        qa_patterns = [
            r'^[é—®é¢˜|æé—®|ä¸»æŒäºº|å˜‰å®¾][:ï¼š]',
            r'^Q[:ï¼š]',
            r'^A[:ï¼š]',
            r'é‚£ä¹ˆ.*é—®é¢˜æ˜¯',
            r'ä½ è§‰å¾—.*å—[ï¼Ÿ?]',
            r'æ€ä¹ˆ.*çœ‹.*[ï¼Ÿ?]'
        ]
        
        paragraph_lower = paragraph.lower()
        
        # æ£€æŸ¥ä¸»é¢˜æŒ‡ç¤ºè¯
        for indicator in topic_indicators:
            if indicator in paragraph_lower:
                return True
        
        # æ£€æŸ¥é—®ç­”æ¨¡å¼
        for pattern in qa_patterns:
            if re.search(pattern, paragraph):
                return True
        
        return False


class PodcastSummarizer:
    """æ’­å®¢æ€»ç»“å™¨ä¸»ç±»"""
    
    def __init__(self, config_path: str = "config.yaml"):
        self.config = self._load_config(config_path)
        if not self.config:
            return
            
        self.segmenter = TextSegmenter(
            min_length=self.config['summarization']['segmentation']['min_segment_length'],
            max_length=self.config['summarization']['segmentation']['max_segment_length'],
            overlap_ratio=self.config['summarization']['segmentation']['overlap_ratio']
        )
        
        # åˆå§‹åŒ–è¿›åº¦ç®¡ç†å™¨
        self.progress_manager = ProgressManager(self.config)
        
        # è·å–é‡è¯•é…ç½®
        self.retry_config = self.config.get('retry', {})
        
        # å¤±è´¥åˆ†æ®µé‡è¯•é…ç½®
        self.failed_segment_retry = {
            'max_attempts': 3,  # å¤±è´¥åˆ†æ®µæœ€å¤§é‡è¯•æ¬¡æ•°
            'base_delay': 10,   # åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
            'max_delay': 60,    # æœ€å¤§å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
            'error_types': {    # é”™è¯¯ç±»å‹å¯¹åº”çš„é‡è¯•ç­–ç•¥
                'timeout': {'retry': True, 'delay_multiplier': 2},
                'rate_limit': {'retry': True, 'delay_multiplier': 3},
                'server_error': {'retry': True, 'delay_multiplier': 1.5},
                'network_error': {'retry': True, 'delay_multiplier': 1.2}
            }
        }
    
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            st.error(f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºé…ç½®æ–‡ä»¶")
            return {}
        except yaml.YAMLError as e:
            st.error(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {str(e)}")
            return {}
    
    def get_available_models(self) -> Dict[str, str]:
        """è·å–å¯ç”¨çš„AIæ¨¡å‹åˆ—è¡¨"""
        models = {}
        for key, model_config in self.config.get('ai_models', {}).items():
            if model_config.get('api_key'):  # åªè¿”å›å·²é…ç½®APIå¯†é’¥çš„æ¨¡å‹
                models[key] = model_config['name']
        return models
    
    def list_incomplete_tasks(self) -> List[TaskProgress]:
        """è·å–æœªå®Œæˆçš„ä»»åŠ¡åˆ—è¡¨"""
        return self.progress_manager.list_incomplete_tasks()
    
    def create_new_task(self, media_title: str, model_key: str) -> TaskProgress:
        """åˆ›å»ºæ–°çš„æ€»ç»“ä»»åŠ¡"""
        task_id = self.progress_manager.generate_task_id(media_title)
        task = TaskProgress(task_id, media_title, model_key)
        self.progress_manager.save_task(task)
        return task
    
    def resume_task(self, task_id: str) -> Optional[TaskProgress]:
        """æ¢å¤å·²å­˜åœ¨çš„ä»»åŠ¡"""
        return self.progress_manager.load_task(task_id)
    
    def delete_task(self, task_id: str) -> bool:
        """åˆ é™¤ä»»åŠ¡"""
        return self.progress_manager.delete_task(task_id)
    
    def _should_retry_failed_segment(self, error_msg: str) -> Tuple[bool, float]:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•å¤±è´¥çš„åˆ†æ®µï¼Œå¹¶è¿”å›å»¶è¿Ÿæ—¶é—´"""
        error_msg = error_msg.lower()
        
        # æ ¹æ®é”™è¯¯ä¿¡æ¯åˆ¤æ–­é”™è¯¯ç±»å‹
        error_type = None
        if 'timeout' in error_msg or 'timed out' in error_msg:
            error_type = 'timeout'
        elif 'rate limit' in error_msg or 'too many requests' in error_msg:
            error_type = 'rate_limit'
        elif 'server error' in error_msg or '500' in error_msg:
            error_type = 'server_error'
        elif 'network' in error_msg or 'connection' in error_msg:
            error_type = 'network_error'
        
        if error_type and error_type in self.failed_segment_retry['error_types']:
            strategy = self.failed_segment_retry['error_types'][error_type]
            if strategy['retry']:
                # è®¡ç®—å»¶è¿Ÿæ—¶é—´ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿
                delay = min(
                    self.failed_segment_retry['base_delay'] * strategy['delay_multiplier'],
                    self.failed_segment_retry['max_delay']
                )
                return True, delay
        
        return False, 0

    def _retry_failed_segments(self, client: AIModelClient, task: TaskProgress, progress_callback=None) -> None:
        """é‡è¯•å¤±è´¥çš„åˆ†æ®µ"""
        if not task.failed_segments:
            return
        
        if progress_callback:
            progress_callback(0.8, f"æ­£åœ¨é‡è¯• {len(task.failed_segments)} ä¸ªå¤±è´¥çš„åˆ†æ®µ...")
        
        # æŒ‰å¤±è´¥æ—¶é—´æ’åºï¼Œä¼˜å…ˆå¤„ç†æœ€è¿‘å¤±è´¥çš„åˆ†æ®µ
        task.failed_segments.sort(key=lambda x: x.get('failed_at', ''), reverse=True)
        
        for failed_segment in task.failed_segments[:]:
            segment_index = failed_segment['index']
            error_msg = failed_segment['error']
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•
            should_retry, delay = self._should_retry_failed_segment(error_msg)
            if not should_retry:
                continue
            
            # ç­‰å¾…å»¶è¿Ÿæ—¶é—´
            if delay > 0:
                time.sleep(delay)
            
            try:
                # è·å–åˆ†æ®µå†…å®¹
                segment_content = self.segmenter.get_segment_content(segment_index)
                if not segment_content:
                    continue
                
                # é‡è¯•æ€»ç»“
                summary = self._summarize_segment(client, segment_content, segment_index)
                keywords = []
                
                # æå–å…³é”®è¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.config['summarization']['summary']['include_keywords']:
                    try:
                        keywords = self._extract_keywords(client, segment_content)
                    except Exception as e:
                        st.warning(f"ç¬¬{segment_index}æ®µå…³é”®è¯æå–å¤±è´¥: {str(e)}")
                
                # ä¿å­˜åˆ†æ®µç»“æœ
                segment_data = {
                    'index': segment_index,
                    'original_length': len(segment_content),
                    'summary': summary,
                    'keywords': keywords
                }
                
                task.add_completed_segment(segment_data)
                # ä»å¤±è´¥åˆ—è¡¨ä¸­ç§»é™¤
                task.failed_segments.remove(failed_segment)
                self.progress_manager.save_task(task)
                
                if progress_callback:
                    completed_percentage = len(task.completed_segments) / task.total_segments * 100
                    progress_callback(0.8 + (completed_percentage * 0.1), f"ç¬¬ {segment_index} æ®µé‡è¯•æˆåŠŸ")
            
            except Exception as e:
                # æ›´æ–°å¤±è´¥ä¿¡æ¯
                failed_segment['error'] = str(e)
                failed_segment['failed_at'] = datetime.now().isoformat()
                self.progress_manager.save_task(task)
                
                if progress_callback:
                    progress_callback(0.8, f"ç¬¬ {segment_index} æ®µé‡è¯•å¤±è´¥: {str(e)}")

    def summarize_transcript(self, text: str, model_key: str, progress_callback=None, task: TaskProgress = None) -> Dict:
        """å¯¹è½¬å½•æ–‡æœ¬è¿›è¡Œæ€»ç»“ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ """
        if not self.config:
            raise Exception("é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥")
        
        if model_key not in self.config['ai_models']:
            raise Exception(f"æœªæ‰¾åˆ°æ¨¡å‹é…ç½®: {model_key}")
        
        model_config = self.config['ai_models'][model_key]
        if not model_config.get('api_key'):
            raise Exception(f"æ¨¡å‹ {model_key} çš„APIå¯†é’¥æœªé…ç½®")
        
        client = AIModelClient(model_config, self.retry_config)
        
        # å¦‚æœæ²¡æœ‰ä¼ å…¥ä»»åŠ¡ï¼Œåˆ›å»ºæ–°ä»»åŠ¡
        if task is None:
            # è¿™é‡Œåº”è¯¥ä»å¤–éƒ¨ä¼ å…¥media_titleï¼Œæš‚æ—¶ä½¿ç”¨æˆªå–çš„æ–‡æœ¬å‰50å­—ç¬¦
            media_title = text[:50].replace('\n', ' ').strip()
            task = self.create_new_task(media_title, model_key)
        
        try:
            # 1. æ™ºèƒ½åˆ†æ®µï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆ†æ®µè¿‡ï¼‰
            if task.total_segments == 0:
                if progress_callback:
                    progress_callback(0.05, "æ­£åœ¨è¿›è¡Œæ™ºèƒ½åˆ†æ®µ...")
                
                segments = self.segmenter.segment_by_topic(text)
                task.total_segments = len(segments)
                task.status = "segments_in_progress"
                self.progress_manager.save_task(task)
            else:
                # é‡æ–°åˆ†æ®µï¼ˆç”¨äºæ¢å¤ä»»åŠ¡ï¼‰
                segments = self.segmenter.segment_by_topic(text)
            
            # 2. åˆ†æ®µæ€»ç»“ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
            remaining_segments = self.progress_manager.get_next_segments_to_process(task, segments)
            total_segments = len(segments)
            completed_count = len(task.completed_segments)
            
            if progress_callback:
                progress_callback(0.1, f"å‡†å¤‡å¤„ç†å‰©ä½™ {len(remaining_segments)} ä¸ªåˆ†æ®µ...")
            
            for i, segment in enumerate(remaining_segments):
                try:
                    if progress_callback:
                        current_progress = 0.1 + ((completed_count + i) / total_segments) * 0.7  # 10%-80%ç”¨äºåˆ†æ®µæ€»ç»“
                        progress_callback(current_progress, f"æ­£åœ¨æ€»ç»“ç¬¬ {segment['index']}/{total_segments} æ®µ...")
                    
                    # æ€»ç»“å•ä¸ªåˆ†æ®µ
                    summary = self._summarize_segment(client, segment['content'], segment['index'])
                    keywords = []
                    
                    # æå–å…³é”®è¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if self.config['summarization']['summary']['include_keywords']:
                        try:
                            keywords = self._extract_keywords(client, segment['content'])
                        except Exception as e:
                            st.warning(f"ç¬¬{segment['index']}æ®µå…³é”®è¯æå–å¤±è´¥: {str(e)}")
                    
                    # ä¿å­˜åˆ†æ®µç»“æœ
                    segment_data = {
                        'index': segment['index'],
                        'start_time': segment.get('start_time'),
                        'original_length': segment['length'],
                        'summary': summary,
                        'keywords': keywords
                    }
                    
                    task.add_completed_segment(segment_data)
                    self.progress_manager.save_task(task)  # ç«‹å³ä¿å­˜è¿›åº¦
                    
                    if progress_callback:
                        completed_percentage = len(task.completed_segments) / total_segments * 100
                        progress_callback(current_progress, f"ç¬¬ {segment['index']} æ®µå®Œæˆ ({completed_percentage:.1f}%)")
                
                except Exception as e:
                    error_msg = str(e)
                    st.error(f"ç¬¬{segment['index']}æ®µæ€»ç»“å¤±è´¥: {error_msg}")
                    task.add_failed_segment(segment['index'], error_msg)
                    self.progress_manager.save_task(task)
                    
                    # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªåˆ†æ®µï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
                    continue
            
            # 3. é‡è¯•å¤±è´¥çš„åˆ†æ®µ
            if task.failed_segments:
                self._retry_failed_segments(client, task, progress_callback)
            
            # 4. æ£€æŸ¥åˆ†æ®µæ€»ç»“æ˜¯å¦å®Œæˆ
            all_segments_completed = len(task.completed_segments) == total_segments
            if not all_segments_completed:
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä½†ä¸ç»§ç»­æ€»ä½“æ€»ç»“
                failed_count = len(task.failed_segments)
                completed_count = len(task.completed_segments)
                
                if failed_count > 0:
                    task.status = "segments_in_progress"  # æœ‰å¤±è´¥çš„åˆ†æ®µ
                    if progress_callback:
                        progress_callback(0.8, f"åˆ†æ®µæ€»ç»“éƒ¨åˆ†å®Œæˆ: {completed_count}/{total_segments} æˆåŠŸ, {failed_count} å¤±è´¥")
                else:
                    task.status = "segments_completed"
                    if progress_callback:
                        progress_callback(0.8, f"åˆ†æ®µæ€»ç»“å®Œæˆ: {completed_count}/{total_segments}")
                
                self.progress_manager.save_task(task)
                
                # è¿”å›éƒ¨åˆ†ç»“æœ
                return self._create_partial_result(task, text)
            
            # 5. æ€»ä½“æ€»ç»“ï¼ˆåªæœ‰åœ¨æ‰€æœ‰åˆ†æ®µéƒ½å®Œæˆæ—¶æ‰æ‰§è¡Œï¼‰
            if task.overall_summary is None:
                try:
                    if progress_callback:
                        progress_callback(0.85, "æ­£åœ¨ç”Ÿæˆæ€»ä½“æ€»ç»“...")
                    
                    task.overall_summary = self._generate_overall_summary(client, task.completed_segments, text)
                    self.progress_manager.save_task(task)
                    
                except Exception as e:
                    st.error(f"æ€»ä½“æ€»ç»“å¤±è´¥: {str(e)}")
                    task.status = "segments_completed"  # åˆ†æ®µå®Œæˆä½†æ€»ä½“æ€»ç»“å¤±è´¥
                    self.progress_manager.save_task(task)
                    return self._create_partial_result(task, text)
            
            # 6. ä¸»é¢˜åˆ†æï¼ˆå¦‚æœå¯ç”¨ä¸”è¿˜æ²¡å®Œæˆï¼‰
            if task.topics is None and self.config['summarization']['summary']['include_topics']:
                try:
                    if progress_callback:
                        progress_callback(0.95, "æ­£åœ¨è¿›è¡Œä¸»é¢˜åˆ†æ...")
                    
                    task.topics = self._analyze_topics(client, text)
                    self.progress_manager.save_task(task)
                    
                except Exception as e:
                    st.warning(f"ä¸»é¢˜åˆ†æå¤±è´¥: {str(e)}")
                    task.topics = []  # è®¾ç½®ä¸ºç©ºåˆ—è¡¨è¡¨ç¤ºå·²å°è¯•è¿‡
                    self.progress_manager.save_task(task)
            
            # 7. å®Œæˆä»»åŠ¡
            task.status = "overall_completed"
            self.progress_manager.save_task(task)
            
            if progress_callback:
                progress_callback(1.0, "æ€»ç»“å®Œæˆï¼")
            
            return self._create_final_result(task, text)
            
        except Exception as e:
            # ä¿å­˜é”™è¯¯ä¿¡æ¯
            task.error_info = str(e)
            task.status = "failed"
            self.progress_manager.save_task(task)
            raise e
    
    def _create_partial_result(self, task: TaskProgress, original_text: str) -> Dict:
        """åˆ›å»ºéƒ¨åˆ†ç»“æœï¼ˆç”¨äºåˆ†æ®µæ€»ç»“å®Œæˆä½†æ€»ä½“æ€»ç»“æœªå®Œæˆçš„æƒ…å†µï¼‰"""
        return {
            'segments': task.completed_segments,
            'overall_summary': task.overall_summary or "æ€»ä½“æ€»ç»“å°šæœªå®Œæˆï¼Œè¯·ç»§ç»­ä»»åŠ¡ä»¥ç”Ÿæˆå®Œæ•´æ€»ç»“",
            'topics': task.topics or [],
            'metadata': {
                'total_segments': task.total_segments,
                'completed_segments_count': len(task.completed_segments),
                'failed_segments_count': len(task.failed_segments),
                'original_length': len(original_text),
                'model_used': self.config['ai_models'][task.model_key]['name'],
                'generated_at': task.updated_at,
                'task_id': task.task_id,
                'progress_percentage': task.get_progress_percentage(),
                'status': task.status,
                'is_partial': True
            }
        }
    
    def _create_final_result(self, task: TaskProgress, original_text: str) -> Dict:
        """åˆ›å»ºæœ€ç»ˆç»“æœ"""
        return {
            'segments': task.completed_segments,
            'overall_summary': task.overall_summary,
            'topics': task.topics or [],
            'metadata': {
                'total_segments': task.total_segments,
                'completed_segments_count': len(task.completed_segments),
                'failed_segments_count': len(task.failed_segments),
                'original_length': len(original_text),
                'model_used': self.config['ai_models'][task.model_key]['name'],
                'generated_at': task.updated_at,
                'task_id': task.task_id,
                'progress_percentage': 100.0,
                'status': task.status,
                'is_partial': False
            }
        }
    
    def _summarize_segment(self, client: AIModelClient, content: str, segment_index: int) -> str:
        """æ€»ç»“å•ä¸ªåˆ†æ®µ"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬æ€»ç»“ä¸“å®¶ã€‚è¯·å¯¹ç»™å®šçš„æ’­å®¢è½¬å½•ç‰‡æ®µè¿›è¡Œç®€æ´æ€»ç»“ã€‚
è¦æ±‚ï¼š
1. ç”¨1-2å¥è¯æ¦‚æ‹¬ä¸»è¦å†…å®¹
2. ä¿ç•™å…³é”®ä¿¡æ¯å’Œè§‚ç‚¹
3. è¯­è¨€ç®€æ´æ˜äº†
4. ä¿æŒä¸­æ–‡è¾“å‡º"""
        
        messages = [{
            "role": "user",
            "content": f"è¯·æ€»ç»“ä»¥ä¸‹æ’­å®¢ç‰‡æ®µï¼ˆç¬¬{segment_index}æ®µï¼‰ï¼š\n\n{content}"
        }]
        
        return client.call_api(messages, system_prompt)
    
    def _extract_keywords(self, client: AIModelClient, content: str) -> List[str]:
        """æå–å…³é”®è¯"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªå…³é”®è¯æå–ä¸“å®¶ã€‚è¯·ä»ç»™å®šæ–‡æœ¬ä¸­æå–3-5ä¸ªæœ€é‡è¦çš„å…³é”®è¯ã€‚
è¦æ±‚ï¼š
1. åªè¾“å‡ºå…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”
2. å…³é”®è¯åº”è¯¥æ˜¯åè¯æˆ–ä¸“ä¸šæœ¯è¯­
3. æŒ‰é‡è¦æ€§æ’åº"""
        
        messages = [{
            "role": "user",
            "content": f"è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…³é”®è¯ï¼š\n\n{content}"
        }]
        
        try:
            result = client.call_api(messages, system_prompt)
            return [kw.strip() for kw in result.split(',') if kw.strip()]
        except:
            return []
    
    def _generate_overall_summary(self, client: AIModelClient, segment_summaries: List[Dict], original_text: str) -> str:
        """ç”Ÿæˆæ€»ä½“æ€»ç»“"""
        summaries_text = "\n".join([f"{i+1}. {summary['summary']}" for i, summary in enumerate(segment_summaries)])
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹æ€»ç»“ä¸“å®¶ã€‚åŸºäºå„ä¸ªåˆ†æ®µçš„æ€»ç»“ï¼Œç”Ÿæˆä¸€ä¸ªæ•´ä½“çš„ç»¼åˆæ€»ç»“ã€‚
è¦æ±‚ï¼š
1. 200-300å­—çš„æ€»ç»“
2. æ¦‚æ‹¬å…¨æ–‡çš„ä¸»è¦ä¸»é¢˜å’Œè§‚ç‚¹
3. ä¿æŒé€»è¾‘æ¸…æ™°ï¼Œç»“æ„å®Œæ•´
4. çªå‡ºæœ€é‡è¦çš„è§è§£å’Œç»“è®º
5. ä½¿ç”¨ä¸­æ–‡è¾“å‡º"""
        
        messages = [{
            "role": "user",
            "content": f"åŸºäºä»¥ä¸‹åˆ†æ®µæ€»ç»“ï¼Œè¯·ç”Ÿæˆä¸€ä¸ªæ•´ä½“æ€»ç»“ï¼š\n\n{summaries_text}"
        }]
        
        return client.call_api(messages, system_prompt)
    
    def _analyze_topics(self, client: AIModelClient, content: str) -> List[str]:
        """åˆ†æä¸»è¦ä¸»é¢˜"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸»é¢˜åˆ†æä¸“å®¶ã€‚è¯·åˆ†æç»™å®šæ–‡æœ¬çš„ä¸»è¦ä¸»é¢˜ã€‚
è¦æ±‚ï¼š
1. è¯†åˆ«3-5ä¸ªä¸»è¦ä¸»é¢˜
2. æ¯ä¸ªä¸»é¢˜ç”¨ç®€çŸ­çš„è¯ç»„è¡¨ç¤º
3. æŒ‰é‡è¦æ€§æ’åº
4. åªè¾“å‡ºä¸»é¢˜åˆ—è¡¨ï¼Œç”¨æ¢è¡Œç¬¦åˆ†éš”"""
        
        # ä¸ºé¿å…æ–‡æœ¬è¿‡é•¿ï¼Œå–å‰2000å­—è¿›è¡Œä¸»é¢˜åˆ†æ
        content_sample = content[:2000] if len(content) > 2000 else content
        
        messages = [{
            "role": "user",
            "content": f"è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„ä¸»è¦ä¸»é¢˜ï¼š\n\n{content_sample}"
        }]
        
        try:
            result = client.call_api(messages, system_prompt)
            return [topic.strip() for topic in result.split('\n') if topic.strip()]
        except:
            return []
    
    def deep_analysis(self, text: str, model_key: str) -> str:
        """åŸºäºprompt.txtè¿›è¡Œæ·±åº¦åˆ†æï¼Œæ”¯æŒåˆ†å—å¤„ç†"""
        # é¦–å…ˆæ£€æŸ¥prompt.txtæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        prompt_file = "prompt.txt"  # é»˜è®¤è·¯å¾„
        
        # å¦‚æœé…ç½®æ–‡ä»¶å­˜åœ¨ä¸”æœ‰è‡ªå®šä¹‰è·¯å¾„ï¼Œåˆ™ä½¿ç”¨é…ç½®çš„è·¯å¾„
        if (self.config and 
            'advanced_features' in self.config and 
            'deep_analysis' in self.config['advanced_features'] and 
            'prompt_file_path' in self.config['advanced_features']['deep_analysis']):
            prompt_file = self.config['advanced_features']['deep_analysis']['prompt_file_path']
        
        # æ£€æŸ¥promptæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(prompt_file):
            raise Exception(f"æ·±åº¦åˆ†ææ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨ï¼š{prompt_file}")
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„å¯ç”¨è®¾ç½®ï¼ˆå¦‚æœå­˜åœ¨é…ç½®ï¼‰
        if (self.config and 
            'advanced_features' in self.config and 
            'deep_analysis' in self.config['advanced_features'] and 
            'enabled' in self.config['advanced_features']['deep_analysis'] and 
            not self.config['advanced_features']['deep_analysis']['enabled']):
            raise Exception("æ·±åº¦åˆ†æåŠŸèƒ½åœ¨é…ç½®æ–‡ä»¶ä¸­è¢«ç¦ç”¨ï¼Œå¦‚éœ€ä½¿ç”¨è¯·åœ¨config.yamlä¸­è®¾ç½® advanced_features.deep_analysis.enabled: true")
        
        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                custom_prompt = f.read()
        except Exception as e:
            raise Exception(f"è¯»å–æ·±åº¦åˆ†ææ¨¡æ¿æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")
        
        if not custom_prompt.strip():
            raise Exception("æ·±åº¦åˆ†ææ¨¡æ¿æ–‡ä»¶å†…å®¹ä¸ºç©º")
        
        model_config = self.config['ai_models'][model_key]
        client = AIModelClient(model_config, self.retry_config)
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨åˆ†å—å¤„ç†
        enable_chunking = (self.config and 
                          'advanced_features' in self.config and 
                          'deep_analysis' in self.config['advanced_features'] and 
                          self.config['advanced_features']['deep_analysis'].get('enable_chunking', False))
        
        chunk_size = (self.config and 
                     'advanced_features' in self.config and 
                     'deep_analysis' in self.config['advanced_features'] and 
                     self.config['advanced_features']['deep_analysis'].get('chunk_size', 3000))
        
        # å¦‚æœæ–‡æœ¬è¾ƒé•¿ä¸”å¯ç”¨åˆ†å—å¤„ç†
        if enable_chunking and len(text) > chunk_size:
            st.info(f"ğŸ’¡ æ–‡æœ¬è¾ƒé•¿ï¼ˆ{len(text)}å­—ç¬¦ï¼‰ï¼Œå°†é‡‡ç”¨åˆ†å—å¤„ç†ä»¥æé«˜æˆåŠŸç‡...")
            
            # å°†æ–‡æœ¬åˆ†å—
            chunks = []
            words = text.split()
            current_chunk = []
            current_length = 0
            
            for word in words:
                word_length = len(word)
                if current_length + word_length > chunk_size and current_chunk:
                    chunks.append(' '.join(current_chunk))
                    current_chunk = [word]
                    current_length = word_length
                else:
                    current_chunk.append(word)
                    current_length += word_length
            
            if current_chunk:
                chunks.append(' '.join(current_chunk))
            
            st.info(f"ğŸ“Š æ–‡æœ¬å·²åˆ†ä¸º {len(chunks)} å—è¿›è¡Œå¤„ç†")
            
            # å¤„ç†æ¯ä¸ªå—
            chunk_results = []
            for i, chunk in enumerate(chunks):
                try:
                    st.info(f"ğŸ”„ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(chunks)} å—...")
                    
                    messages = [{
                        "role": "user",
                        "content": f"è¯·å¯¹ä»¥ä¸‹æ’­å®¢å†…å®¹ç‰‡æ®µè¿›è¡Œåˆ†æï¼Œè¿™æ˜¯ç¬¬{i+1}éƒ¨åˆ†ï¼Œå…±{len(chunks)}éƒ¨åˆ†ï¼š\n\nã€åˆ†ææŒ‡å¯¼ã€‘\n{custom_prompt}\n\nã€æ’­å®¢å†…å®¹ç‰‡æ®µã€‘\n{chunk}"
                    }]
                    
                    chunk_result = client.call_api(messages, f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†æä¸“å®¶ã€‚è¿™æ˜¯å¤šæ®µå†…å®¹ä¸­çš„ç¬¬{i+1}æ®µï¼Œè¯·æŒ‰ç…§æŒ‡å¯¼åŸåˆ™è¿›è¡Œåˆ†æã€‚")
                    chunk_results.append(f"## ç¬¬{i+1}éƒ¨åˆ†åˆ†æ\n\n{chunk_result}")
                    
                except Exception as e:
                    st.warning(f"âš ï¸ ç¬¬ {i+1} å—å¤„ç†å¤±è´¥ï¼š{str(e)}")
                    chunk_results.append(f"## ç¬¬{i+1}éƒ¨åˆ†åˆ†æ\n\n[å¤„ç†å¤±è´¥: {str(e)}]")
            
            # åˆå¹¶ç»“æœ
            if chunk_results:
                final_result = "\n\n".join(chunk_results)
                
                # å¦‚æœæ‰€æœ‰å—éƒ½å¤„ç†æˆåŠŸï¼Œå°è¯•ç”Ÿæˆæ•´ä½“æ€»ç»“
                if len([r for r in chunk_results if "[å¤„ç†å¤±è´¥" not in r]) == len(chunks):
                    try:
                        st.info("ğŸ”„ æ­£åœ¨ç”Ÿæˆæ•´ä½“æ€»ç»“...")
                        summary_messages = [{
                            "role": "user",
                            "content": f"è¯·åŸºäºä»¥ä¸‹å„éƒ¨åˆ†çš„åˆ†æï¼Œç”Ÿæˆä¸€ç¯‡å®Œæ•´ç»Ÿä¸€çš„æ·±åº¦åˆ†ææ–‡ç« ï¼š\n\n{final_result}"
                        }]
                        
                        overall_summary = client.call_api(summary_messages, "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹æ•´åˆä¸“å®¶ï¼Œè¯·å°†åˆ†æ®µåˆ†ææ•´åˆä¸ºä¸€ç¯‡è¿è´¯çš„å®Œæ•´æ–‡ç« ã€‚")
                        return overall_summary
                        
                    except Exception as e:
                        st.warning(f"âš ï¸ æ•´ä½“æ€»ç»“ç”Ÿæˆå¤±è´¥ï¼Œè¿”å›åˆ†å—ç»“æœï¼š{str(e)}")
                        return final_result
                else:
                    return final_result
            else:
                raise Exception("æ‰€æœ‰åˆ†å—å¤„ç†éƒ½å¤±è´¥äº†")
        else:
            # æ­£å¸¸å¤„ç†ï¼ˆä¸åˆ†å—ï¼‰
            messages = [{
                "role": "user",
                "content": f"è¯·æ ¹æ®ä»¥ä¸‹æŒ‡å¯¼åŸåˆ™å¯¹æ’­å®¢å†…å®¹è¿›è¡Œæ·±åº¦åˆ†æï¼š\n\nã€åˆ†ææŒ‡å¯¼ã€‘\n{custom_prompt}\n\nã€æ’­å®¢å†…å®¹ã€‘\n{text}"
            }]
            
            return client.call_api(messages, "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†æä¸“å®¶ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§ç»™å®šçš„æŒ‡å¯¼åŸåˆ™è¿›è¡Œåˆ†æã€‚")
    
    def export_summary(self, summary_data: Dict, format_type: str, filename: str) -> str:
        """å¯¼å‡ºæ€»ç»“åˆ°ä¸åŒæ ¼å¼"""
        if format_type == "markdown":
            return self._export_to_markdown(summary_data, filename)
        elif format_type == "pdf":
            return self._export_to_pdf(summary_data, filename)
        elif format_type == "txt":
            return self._export_to_txt(summary_data, filename)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format_type}")
    
    def _export_to_markdown(self, summary_data: Dict, filename: str) -> str:
        """å¯¼å‡ºä¸ºMarkdownæ ¼å¼"""
        md_content = f"""# æ’­å®¢æ€»ç»“æŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **ç”Ÿæˆæ—¶é—´**: {summary_data['metadata']['generated_at']}
- **ä½¿ç”¨æ¨¡å‹**: {summary_data['metadata']['model_used']}
- **åˆ†æ®µæ•°é‡**: {summary_data['metadata']['total_segments']}
- **åŸæ–‡é•¿åº¦**: {summary_data['metadata']['original_length']}å­—

## æ€»ä½“æ€»ç»“

{summary_data['overall_summary']}

## ä¸»è¦ä¸»é¢˜
"""
        
        if summary_data['topics']:
            for i, topic in enumerate(summary_data['topics'], 1):
                md_content += f"{i}. {topic}\n"
        else:
            md_content += "æš‚æ— ä¸»é¢˜åˆ†æ\n"
        
        md_content += "\n## åˆ†æ®µæ€»ç»“\n\n"
        
        for segment in summary_data['segments']:
            md_content += f"### ç¬¬{segment['index']}æ®µ"
            if segment['start_time']:
                md_content += f" ({segment['start_time']})"
            md_content += "\n\n"
            md_content += f"{segment['summary']}\n\n"
            
            if segment['keywords']:
                md_content += f"**å…³é”®è¯**: {', '.join(segment['keywords'])}\n\n"
        
        # ä¿å­˜æ–‡ä»¶
        output_path = f"{filename}_summary.md"
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        return output_path
    
    def _export_to_txt(self, summary_data: Dict, filename: str) -> str:
        """å¯¼å‡ºä¸ºçº¯æ–‡æœ¬æ ¼å¼"""
        txt_content = f"""æ’­å®¢æ€»ç»“æŠ¥å‘Š

åŸºæœ¬ä¿¡æ¯ï¼š
ç”Ÿæˆæ—¶é—´: {summary_data['metadata']['generated_at']}
ä½¿ç”¨æ¨¡å‹: {summary_data['metadata']['model_used']}
åˆ†æ®µæ•°é‡: {summary_data['metadata']['total_segments']}
åŸæ–‡é•¿åº¦: {summary_data['metadata']['original_length']}å­—

æ€»ä½“æ€»ç»“ï¼š
{summary_data['overall_summary']}

ä¸»è¦ä¸»é¢˜ï¼š
"""
        
        if summary_data['topics']:
            for i, topic in enumerate(summary_data['topics'], 1):
                txt_content += f"{i}. {topic}\n"
        else:
            txt_content += "æš‚æ— ä¸»é¢˜åˆ†æ\n"
        
        txt_content += "\nåˆ†æ®µæ€»ç»“ï¼š\n\n"
        
        for segment in summary_data['segments']:
            txt_content += f"ç¬¬{segment['index']}æ®µ"
            if segment['start_time']:
                txt_content += f" ({segment['start_time']})"
            txt_content += "ï¼š\n"
            txt_content += f"{segment['summary']}\n"
            
            if segment['keywords']:
                txt_content += f"å…³é”®è¯: {', '.join(segment['keywords'])}\n"
            txt_content += "\n"
        
        # ä¿å­˜æ–‡ä»¶
        output_path = f"{filename}_summary.txt"
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(txt_content)
        
        return output_path
    
    def _export_to_pdf(self, summary_data: Dict, filename: str) -> str:
        """å¯¼å‡ºä¸ºPDFæ ¼å¼"""
        output_path = f"{filename}_summary.pdf"
        
        # åˆ›å»ºPDFæ–‡æ¡£
        doc = SimpleDocTemplate(output_path, pagesize=A4)
        story = []
        styles = getSampleStyleSheet()
        
        # å°è¯•æ³¨å†Œä¸­æ–‡å­—ä½“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            # è¿™é‡Œå¯ä»¥æ ¹æ®ç³»ç»Ÿæ·»åŠ ä¸­æ–‡å­—ä½“è·¯å¾„
            # pdfmetrics.registerFont(TTFont('SimSun', 'SimSun.ttf'))
            pass
        except:
            pass
        
        # æ ‡é¢˜
        title = Paragraph("æ’­å®¢æ€»ç»“æŠ¥å‘Š", styles['Title'])
        story.append(title)
        story.append(Spacer(1, 12))
        
        # åŸºæœ¬ä¿¡æ¯
        info_text = f"""ç”Ÿæˆæ—¶é—´: {summary_data['metadata']['generated_at']}<br/>
ä½¿ç”¨æ¨¡å‹: {summary_data['metadata']['model_used']}<br/>
åˆ†æ®µæ•°é‡: {summary_data['metadata']['total_segments']}<br/>
åŸæ–‡é•¿åº¦: {summary_data['metadata']['original_length']}å­—"""
        
        info = Paragraph(info_text, styles['Normal'])
        story.append(info)
        story.append(Spacer(1, 12))
        
        # æ€»ä½“æ€»ç»“
        summary_title = Paragraph("æ€»ä½“æ€»ç»“", styles['Heading2'])
        story.append(summary_title)
        summary_content = Paragraph(summary_data['overall_summary'], styles['Normal'])
        story.append(summary_content)
        story.append(Spacer(1, 12))
        
        # ä¸»è¦ä¸»é¢˜
        if summary_data['topics']:
            topics_title = Paragraph("ä¸»è¦ä¸»é¢˜", styles['Heading2'])
            story.append(topics_title)
            topics_text = "<br/>".join([f"{i}. {topic}" for i, topic in enumerate(summary_data['topics'], 1)])
            topics_content = Paragraph(topics_text, styles['Normal'])
            story.append(topics_content)
            story.append(Spacer(1, 12))
        
        # åˆ†æ®µæ€»ç»“
        segments_title = Paragraph("åˆ†æ®µæ€»ç»“", styles['Heading2'])
        story.append(segments_title)
        
        for segment in summary_data['segments']:
            segment_title_text = f"ç¬¬{segment['index']}æ®µ"
            if segment['start_time']:
                segment_title_text += f" ({segment['start_time']})"
            
            segment_title = Paragraph(segment_title_text, styles['Heading3'])
            story.append(segment_title)
            
            segment_content = Paragraph(segment['summary'], styles['Normal'])
            story.append(segment_content)
            
            if segment['keywords']:
                keywords_text = f"å…³é”®è¯: {', '.join(segment['keywords'])}"
                keywords = Paragraph(keywords_text, styles['Normal'])
                story.append(keywords)
            
            story.append(Spacer(1, 12))
        
        # æ„å»ºPDF
        doc.build(story)
        return output_path 